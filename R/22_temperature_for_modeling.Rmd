---
title: "22_temperature_for_modeling"
author: "Markus Min"
date: "2023-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# load libraries
library(here)
library(janitor)
library(tidyverse)
library(lubridate)
library(car)
library(ggthemes)
library(zoo)
library(ggpubr)
```

## Description

This Rmd will prepare temperature data for inclusion in the model. Much of the code is borrowed from 20_covariate_data.Rmd, but is trimmed down to only what is needed to generate a gap-less temperature dataset.

There is a considerable amount of missing temperature data. To interpolate missing values, we will use the following protocol to determine where temperature data is drawn from:

1.  If tailrace temperature data is available, use tailrace temperature data
2.  If tailrace temperature data is not available but forebay temperature is, use the forebay temperature
3.  If the gap of temperatures is less than one week, linearly interpolate between those two points
4.  If neither is available, use the relationship between temperature at the current dam and temperature at a nearby dam to interpolate (we will determine what that relationship is in this script)
5.  If no dam has available temperature data for the date in question, use a linear interpolation between the last two temperature data points.

Throughout all of this, we will make sure to record how each temperature data point was generated for QA/QC purposes.

```{r functions}

# Function 1: reformat covariate data
cov_reformat <- function(input_data, variable_name){
  
  # need to deal with leap years
  leap_years <- seq(1960, 2024, by = 4)
  
  input_data %>% 
    pivot_longer(., cols = colnames(.)[2:ncol(.)]) %>% 
    dplyr::rename(year = name,
                  !!quo_name(variable_name) := value) %>% 
    mutate(year = gsub("X","",year)) %>% 
    mutate(year = as.numeric(year), day = as.numeric(day)) %>% 
    # drop day 366 in non-leap years
    dplyr::filter(!(day == 366 & !(year %in% leap_years))) %>%
    # Add a new column for date (combine year and day)
    mutate(date = format(as.Date(day, origin = paste0(year-1, "-12-31")))) %>% 
    arrange(year, day) %>% 
    # drop all years before 2005
    filter(year >= 2005) -> output_data
  
  
  return(output_data)
}

# Function 2: combine covariate data into df with date, spill, flow, and temp columns
cov_combine <- function(flow_data, spill_data, temp_data){
  flow_data %>% 
  left_join(., dplyr::select(spill_data, spill, date), by = "date") %>% 
  left_join(., dplyr::select(temp_data, temp, date), by = "date") %>% 
  mutate(date = ymd(date)) %>% 
  # keep only 2004 onwards (years that have data for all cov)
  subset(date >= ymd("2004-01-01")) -> cont_cov
  
  return(cont_cov)
  
}


# Function 3: quantify data availability
cov_data_availability <- function(cont_cov){
  cont_cov %>% 
  mutate(data_available = ifelse(is.na(flow) & !(is.na(spill)) & !(is.na(temp)), "spill + temp",
                                 ifelse(is.na(flow) & is.na(spill) & !(is.na(temp)), "temp",
                                        ifelse(is.na(flow) & (is.na(spill)) & (is.na(temp)), "none",
                                               ifelse(!(is.na(flow)) & !(is.na(spill)) & !(is.na(temp)), "spill + temp + flow",
                                                      ifelse(!(is.na(flow)) & !(is.na(spill)) & (is.na(temp)), "spill + flow",
                                                             ifelse(!(is.na(flow)) & (is.na(spill)) & (is.na(temp)), "flow",
                                                                    ifelse((is.na(flow)) & !(is.na(spill)) & (is.na(temp)), "spill",
                                                                           ifelse(!(is.na(flow)) & (is.na(spill)) & !(is.na(temp)), "temp + flow",
                                                                                  "ERROR"))))))))) %>% 
  # make them factors for plotting
  mutate(data_available = fct_rev(factor(data_available, levels = c("spill + temp + flow", "spill + flow", 
                                                            "temp + flow", "spill + temp",
                                                            "temp", "flow", "spill", "none")))) -> cont_cov
  
  return(cont_cov)
}

# Function 3.5 - a different function to quantify just missing data
cov_data_availability_2 <- function(cont_cov) {
  cont_cov %>% 
    # Make a different column where it just shows missing data (this should be simpler) 
  mutate(temp_avail = ifelse(is.na(temp), NA, "temp")) %>% 
  mutate(flow_avail = ifelse(is.na(flow), NA, "flow")) %>% 
  mutate(spill_avail = ifelse(is.na(spill), NA, "spill")) %>% 
  dplyr::select(date, temp_avail, flow_avail, spill_avail) %>% 
  pivot_longer(cols = c(temp_avail, flow_avail, spill_avail))-> data_avail_df

  data_avail_plot <- ggplot(subset(data_avail_df, !(is.na(value))), aes(x = date, y = value)) +
    geom_point() +
    ylab("Data Availability")
  
  return(data_avail_plot)
}



# Function 4: Data availabilty visualization
cov_data_viz <- function(cont_cov) {
  
  
# okay, is there a pattern seasonally?
# data_avail_plot <- ggplot(cont_cov, aes(x = date, y = data_available)) +
#   geom_point() +
#   scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
#   theme(panel.grid.minor = element_blank(),
#         axis.text = element_text(size = 7))
# 
# # v2 - missing data only
# data_avail_plot <- ggplot(cont_cov, aes(x = date, y = missing_data)) +
#   geom_point() +
#   scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
#   theme(panel.grid.minor = element_blank(),
#         axis.text = element_text(size = 7))

temp_plot <- ggplot(cont_cov, aes(x = day, y = temp)) +
  geom_point() +
  scale_x_continuous(breaks = c(0,50,100,150,200,250,300,365))

flow_plot <- ggplot(cont_cov, aes(x = day, y = flow)) +
  geom_point() +
  scale_x_continuous(breaks = c(0,50,100,150,200,250,300,365))

spill_plot <- ggplot(cont_cov, aes(x = day, y = spill)) +
  geom_point() +
  scale_x_continuous(breaks = c(0,50,100,150,200,250,300,365))

# plot_list <- list(data_avail_plot, temp_plot, flow_plot, spill_plot)
plot_list <- list(temp_plot, flow_plot, spill_plot)

return(plot_list)

}

# Function 5: Plot regressions, return VIF and R^2
cov_regressions <- function(cont_cov){
  
# plot
flow_v_spill <- ggplot(cont_cov, aes(x = flow, y = spill)) +
  geom_point()

flow_v_temp <- ggplot(cont_cov, aes(x = flow, y = temp)) +
  geom_point()

temp_v_spill <- ggplot(cont_cov, aes(x = temp, y = spill)) +
  geom_point()

# reg_plots <- list(flow_v_spill, flow_v_temp, temp_v_spill)

# run regressions
spill_flow_lm <- lm(spill~flow, data = cont_cov)
spill_flow_lm_sum <- summary(spill_flow_lm)

temp_flow_lm <- lm(temp~flow, data = cont_cov)
temp_flow_lm_sum <- summary(temp_flow_lm)

spill_temp_lm <- lm(spill~temp, data = cont_cov)
spill_temp_lm_sum <-summary(spill_temp_lm)

return(list(flow_v_spill, spill_flow_lm_sum,
            flow_v_temp, temp_flow_lm_sum,
            temp_v_spill, spill_temp_lm_sum))
}

# Function 6: Variance inflation factors
cov_vif <- function(cont_cov){
  # run multiple linear regressions and calculate VIF
  spill_mlm <- lm(spill ~ flow + temp, data = cont_cov)
  spill_vif <- vif(spill_mlm)

  temp_mlm <- lm(temp ~ flow + spill, data = cont_cov)
  temp_vif <- vif(temp_mlm)

  flow_mlm <- lm(flow ~ spill + temp, data = cont_cov)
  flow_vif <- vif(flow_mlm)
  
  return(list(spill_vif, temp_vif, flow_vif))
} 

# Function 7: Generate plot and regression of forebay vs. tailrace temperature  
forebay_v_tailrace <- function(forebay_t, tailrace_t, dam){
  # reformat into one df
dplyr::select(forebay_t, c(temp, date)) %>% 
  dplyr::rename(forebay_temp = temp) -> forebay_t_forjoin

tailrace_t %>% 
  dplyr::rename(tailrace_temp = temp) %>% 
  dplyr::select(tailrace_temp, date) %>% 
  left_join(., forebay_t_forjoin, by = "date") -> temp_comparison

# get the lm fit
lm_fit <- lm(forebay_temp~tailrace_temp, data = temp_comparison)

# generate plot
forebay_v_tailrace_plot <- ggplot(subset(temp_comparison, !is.na(tailrace_temp) & !(is.na(forebay_temp))), 
                                  aes(y = forebay_temp, x = tailrace_temp)) +
  geom_point() +
  ggtitle(dam) +
  scale_x_continuous(lim = c(0, 28)) +
  scale_y_continuous(lim = c(0, 28)) +
  annotate(geom = "text", x = 2, y = 20, hjust = 0,
           label = paste0("y = ", round(lm_fit$coefficients[1],3), " + ", round(lm_fit$coefficients[2],3)," * x"))

# return plot and equation
# return(list(forebay_v_tailrace_plot, lm_fit))
return(forebay_v_tailrace_plot)
}

# Function 8: Plot ts of forebay and tailrace temperatures
plot_temp_ts <- function(forebay_t, tailrace_t, dam){
  forebay_t %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(month = as.factor(month(date))) -> forebay_t
  
  tailrace_t %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(month = as.factor(month(date))) -> tailrace_t
  
  forebay_t_ts <- ggplot(forebay_t, aes(x = day, y = temp, color = year)) +
    geom_point() +
    ggtitle(dam) +
    ylab("Forebay T")
  
  tailrace_t_ts <- ggplot(tailrace_t, aes(x = day, y = temp, color = year)) +
    geom_point() +
    ggtitle(dam) +
    ylab("Tailrace T")
  
  two_plots <- ggarrange(forebay_t_ts, tailrace_t_ts, ncol = 1)
  
  return(two_plots)
}

# Function 9: Filter out the outliers based on +/- 4 degrees, as well as based on 
# a moving average of seven days, and if it's more than 2 degrees outside that moving average, drop it
# issue with this is that we get runs of outliers that aren't dropped by that alone, which is why we need the first step to take out major outliers
filter_outliers_temp <- function(forebay_t, tailrace_t, dam){
  forebay_t %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(month = as.factor(month(date))) -> forebay_t
  
  # get a moving average using rollapply()
  # forebay_t %>% 
  #   mutate(MA = rollapply(temp, 7 , mean, na.rm = TRUE, align='center', fill = NA)) %>% 
  #   # if it's the beginning or end of the TS, then MA will be NA, so replace those with the temperature (so these won't be dropped)
  #   mutate(MA = ifelse(is.na(MA), temp, MA)) %>% 
  #   filter(abs(temp - MA) <= 2) %>% 
  #   dplyr::select(date, temp) %>%
  #   dplyr::rename(forebay_temp = temp)-> forebay_t_filtered
  
  forebay_t %>%
    group_by(day) %>%
    summarise(day_mean = mean(temp, na.rm = TRUE)) -> forebay_t_daily_means

  forebay_t %>%
    # filter based on major outliers
    left_join(., forebay_t_daily_means, by = "day") %>%
    filter(abs(temp - day_mean) <= 4) %>%
    # filter based on moving average
    mutate(MA = rollapply(temp, 7 , mean, na.rm = TRUE, align='center', fill = NA)) %>%
    # if it's the beginning or end of the TS, then MA will be NA, so replace those with the temperature (so these won't be dropped)
    mutate(MA = ifelse(is.na(MA), temp, MA)) %>%
    filter(abs(temp - MA) <= 2) %>%
    dplyr::select(date, temp) %>%
    dplyr::rename(forebay_temp = temp)-> forebay_t_filtered
  
  tailrace_t %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(month = as.factor(month(date))) -> tailrace_t
  
  # tailrace_t %>% 
  #   mutate(MA = rollapply(temp, 7 , mean, na.rm = TRUE, align='center', fill = NA)) %>% 
  #   # if it's the beginning or end of the TS, then MA will be NA, so replace those with the temperature (so these won't be dropped)
  #   mutate(MA = ifelse(is.na(MA), temp, MA)) %>% 
  #   filter(abs(temp - MA) <= 2) %>% 
  #       dplyr::select(date, temp) %>%
  #   dplyr::rename(tailrace_temp = temp)-> tailrace_t_filtered
  
  tailrace_t %>%
    group_by(day) %>%
    summarise(day_mean = mean(temp, na.rm = TRUE)) -> tailrace_t_daily_means

  tailrace_t %>%
    left_join(., tailrace_t_daily_means, by = "day") %>%
    filter(abs(temp - day_mean) <= 4) %>%
    # filter based on moving average
    mutate(MA = rollapply(temp, 7 , mean, na.rm = TRUE, align='center', fill = NA)) %>%
    # if it's the beginning or end of the TS, then MA will be NA, so replace those with the temperature (so these won't be dropped)
    mutate(MA = ifelse(is.na(MA), temp, MA)) %>%
    filter(abs(temp - MA) <= 2) %>%
    dplyr::select(date, temp) %>%
    dplyr::rename(tailrace_temp = temp)-> tailrace_t_filtered
  
  return(list(forebay_t_filtered, tailrace_t_filtered))
}
```

Here, we will distinguish between forebay ("f") and tailrace ("t") temperature at each dam

```{r load_data}
# BON
BON_temp_t <- read.csv(here::here("covariate_data", "BON", "basin_tempc_tailrace_BON_allyears.csv"))[1:366,]
BON_temp_t_long <- cov_reformat(input_data = BON_temp_t, variable_name = "temp")
BON_temp_f <- read.csv(here::here("covariate_data", "BON", "basin_tempc_BON_allyears.csv"))[1:366,]
BON_temp_f_long <- cov_reformat(input_data = BON_temp_f, variable_name = "temp")

# ICH
ICH_temp_t <- read.csv(here::here("covariate_data", "ICH", "basin_tempc_tailrace_IHR_allyears.csv"))[1:366,]
ICH_temp_t_long <- cov_reformat(input_data = ICH_temp_t, variable_name = "temp")
ICH_temp_f <- read.csv(here::here("covariate_data", "ICH", "basin_tempc_IHR_allyears.csv"))[1:366,]
ICH_temp_f_long <- cov_reformat(input_data = ICH_temp_f, variable_name = "temp")


# JDA
JDA_temp_t <- read.csv(here::here("covariate_data", "JDA", "basin_tempc_tailrace_JDA_allyears.csv"))[1:366,]
JDA_temp_t_long <- cov_reformat(input_data = JDA_temp_t, variable_name = "temp")
JDA_temp_f <- read.csv(here::here("covariate_data", "JDA", "basin_tempc_JDA_allyears.csv"))[1:366,]
JDA_temp_f_long <- cov_reformat(input_data = JDA_temp_f, variable_name = "temp")


# TDA
TDA_temp_t <- read.csv(here::here("covariate_data", "TDA", "basin_tempc_tailrace_TDA_allyears.csv"))[1:366,]
TDA_temp_long <- cov_reformat(input_data = TDA_temp_t, variable_name = "temp")
TDA_temp_f <- read.csv(here::here("covariate_data", "TDA", "basin_tempc_TDA_allyears.csv"))[1:366,]
TDA_temp_f_long <- cov_reformat(input_data = TDA_temp_f, variable_name = "temp")

# LGR
LGR_temp_t <- read.csv(here::here("covariate_data", "LGR", "basin_tempc_tailrace_LWG_allyears.csv"))[1:366,]
LGR_temp_t_long <- cov_reformat(input_data = LGR_temp_t, variable_name = "temp")
LGR_temp_f <- read.csv(here::here("covariate_data", "LGR", "basin_tempc_LWG_allyears.csv"))[1:366,]
LGR_temp_f_long <- cov_reformat(input_data = LGR_temp_f, variable_name = "temp")

# LMO
LMO_temp_t <- read.csv(here::here("covariate_data", "LMO", "basin_tempc_tailrace_LMN_allyears.csv"))[1:366,]
LMO_temp_t_long <- cov_reformat(input_data = LMO_temp_t, variable_name = "temp")
LMO_temp_f <- read.csv(here::here("covariate_data", "LMO", "basin_tempc_LMN_allyears.csv"))[1:366,]
LMO_temp_f_long <- cov_reformat(input_data = LMO_temp_f, variable_name = "temp")

# LGO
LGO_temp_t <- read.csv(here::here("covariate_data", "LGO", "basin_tempc_tailrace_LGS_allyears.csv"))[1:366,]
LGO_temp_t_long <- cov_reformat(input_data = LGO_temp_t, variable_name = "temp")
LGO_temp_f <- read.csv(here::here("covariate_data", "LGO", "basin_tempc_LGS_allyears.csv"))[1:366,]
LGO_temp_f_long <- cov_reformat(input_data = LGO_temp_f, variable_name = "temp")


# MCN
MCN_temp_t <- read.csv(here::here("covariate_data", "MCN", "basin_tempc_tailrace_MCN_allyears.csv"))[1:366,]
MCN_temp_t_long <- cov_reformat(input_data = MCN_temp_t, variable_name = "temp")
MCN_temp_f <- read.csv(here::here("covariate_data", "MCN", "basin_tempc_MCN_allyears.csv"))[1:366,]
MCN_temp_f_long <- cov_reformat(input_data = MCN_temp_f, variable_name = "temp")


# PRA
PRA_temp_t <- read.csv(here::here("covariate_data", "PRA", "basin_tempc_tailrace_PRD_allyears.csv"))[1:366,]
PRA_temp_t_long <- cov_reformat(input_data = PRA_temp_t, variable_name = "temp")
PRA_temp_f <- read.csv(here::here("covariate_data", "PRA", "basin_tempc_PRD_allyears.csv"))[1:366,]
PRA_temp_f_long <- cov_reformat(input_data = PRA_temp_f, variable_name = "temp")


# RIS
RIS_temp_t <- read.csv(here::here("covariate_data", "RIS", "basin_tempc_tailrace_RIS_allyears.csv"))[1:366,]
RIS_temp_t_long <- cov_reformat(input_data = RIS_temp_t, variable_name = "temp")
RIS_temp_f <- read.csv(here::here("covariate_data", "RIS", "basin_tempc_RIS_allyears.csv"))[1:366,]
RIS_temp_f_long <- cov_reformat(input_data = RIS_temp_f, variable_name = "temp")


# RRE
RRE_temp_t <- read.csv(here::here("covariate_data", "RRE", "basin_tempc_tailrace_RRH_allyears.csv"))[1:366,]
RRE_temp_t_long <- cov_reformat(input_data = RRE_temp_t, variable_name = "temp")
RRE_temp_f <- read.csv(here::here("covariate_data", "RRE", "basin_tempc_RRH_allyears.csv"))[1:366,]
RRE_temp_f_long <- cov_reformat(input_data = RRE_temp_f, variable_name = "temp")

# TDA
TDA_temp_t <- read.csv(here::here("covariate_data", "TDA", "basin_tempc_tailrace_TDA_allyears.csv"))[1:366,]
TDA_temp_t_long <- cov_reformat(input_data = TDA_temp_t, variable_name = "temp")
TDA_temp_f <- read.csv(here::here("covariate_data", "TDA", "basin_tempc_TDA_allyears.csv"))[1:366,]
TDA_temp_f_long <- cov_reformat(input_data = TDA_temp_f, variable_name = "temp")


# WEL
WEL_temp_t <- read.csv(here::here("covariate_data", "WEL", "basin_tempc_tailrace_WEL_allyears.csv"))[1:366,]
WEL_temp_t_long <- cov_reformat(input_data = WEL_temp_t, variable_name = "temp")
WEL_temp_f <- read.csv(here::here("covariate_data", "WEL", "basin_tempc_WEL_allyears.csv"))[1:366,]
WEL_temp_f_long <- cov_reformat(input_data = WEL_temp_f, variable_name = "temp")

# WAN
WAN_temp_t <- read.csv(here::here("covariate_data", "WAN", "basin_tempc_tailrace_WAN_allyears.csv"))[1:366,]
WAN_temp_t_long <- cov_reformat(input_data = WAN_temp_t, variable_name = "temp")
WAN_temp_f <- read.csv(here::here("covariate_data", "WAN", "basin_tempc_WAN_allyears.csv"))[1:366,]
WAN_temp_f_long <- cov_reformat(input_data = WAN_temp_f, variable_name = "temp")
```

### plot forebay vs. tailrace temperature

```{r}
forebay_v_tailrace(forebay_t = BON_temp_f_long, tailrace_t = BON_temp_t_long, dam = "BON")
forebay_v_tailrace(forebay_t = ICH_temp_f_long, tailrace_t = ICH_temp_t_long, dam = "ICH")
forebay_v_tailrace(forebay_t = JDA_temp_f_long, tailrace_t = JDA_temp_t_long, dam = "JDA")
forebay_v_tailrace(forebay_t = LGO_temp_f_long, tailrace_t = LGO_temp_t_long, dam = "LGO")
forebay_v_tailrace(forebay_t = LGR_temp_f_long, tailrace_t = LGR_temp_t_long, dam = "LGR")
forebay_v_tailrace(forebay_t = LMO_temp_f_long, tailrace_t = LMO_temp_t_long, dam = "LMO")
forebay_v_tailrace(forebay_t = MCN_temp_f_long, tailrace_t = MCN_temp_t_long, dam = "MCN")
forebay_v_tailrace(forebay_t = PRA_temp_f_long, tailrace_t = PRA_temp_t_long, dam = "PRA")
forebay_v_tailrace(forebay_t = RIS_temp_f_long, tailrace_t = RIS_temp_t_long, dam = "RIS")
forebay_v_tailrace(forebay_t = RRE_temp_f_long, tailrace_t = RRE_temp_t_long, dam = "RRE")
forebay_v_tailrace(forebay_t = TDA_temp_f_long, tailrace_t = TDA_temp_t_long, dam = "TDA")
forebay_v_tailrace(forebay_t = WAN_temp_f_long, tailrace_t = WAN_temp_t_long, dam = "WAN")
forebay_v_tailrace(forebay_t = WEL_temp_f_long, tailrace_t = WEL_temp_t_long, dam = "WEL")
```

### data filtering

there are some complete nonsense values that it looks like we will have to filter. Worst offenders are RIS, RRE, and WEL. Is it the forebay or tailrace temperatures that are bad? Turns out both

```{r}
plot_temp_ts(forebay_t = BON_temp_f_long, tailrace_t = BON_temp_t_long, dam = "BON")
plot_temp_ts(forebay_t = ICH_temp_f_long, tailrace_t = ICH_temp_t_long, dam = "ICH")
plot_temp_ts(forebay_t = JDA_temp_f_long, tailrace_t = JDA_temp_t_long, dam = "JDA")
plot_temp_ts(forebay_t = LGO_temp_f_long, tailrace_t = LGO_temp_t_long, dam = "LGO")
plot_temp_ts(forebay_t = LGR_temp_f_long, tailrace_t = LGR_temp_t_long, dam = "LGR")
plot_temp_ts(forebay_t = LMO_temp_f_long, tailrace_t = LMO_temp_t_long, dam = "LMO")
plot_temp_ts(forebay_t = MCN_temp_f_long, tailrace_t = MCN_temp_t_long, dam = "MCN")
plot_temp_ts(forebay_t = PRA_temp_f_long, tailrace_t = PRA_temp_t_long, dam = "PRA")
plot_temp_ts(forebay_t = RIS_temp_f_long, tailrace_t = RIS_temp_t_long, dam = "RIS")
plot_temp_ts(forebay_t = RRE_temp_f_long, tailrace_t = RRE_temp_t_long, dam = "RRE")
plot_temp_ts(forebay_t = TDA_temp_f_long, tailrace_t = TDA_temp_t_long, dam = "TDA")
plot_temp_ts(forebay_t = WAN_temp_f_long, tailrace_t = WAN_temp_t_long, dam = "WAN")
plot_temp_ts(forebay_t = WEL_temp_f_long, tailrace_t = WEL_temp_t_long, dam = "WEL")
```

### filtering function

Two steps: 1. For total nonsense runs of values (RIS, RRE, and WEL) - manually select and drop those days 2. Drop outliers - see chunk below

```{r filter_Wells}
# WEL, forebay
WEL_temp_f_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> WEL_temp_f_long_2

ggplot(WEL_temp_f_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("Wells Forebay T, Original")

# run of values in 2009
# subset(WEL_temp_f_long, year == 2009)
# nonsense starts on day 270 and end on day 300

WEL_temp_f_long %>% 
  filter(!(year == 2009 & day >= 270 & day <=300)) -> WEL_temp_f_long_clean

ggplot(WEL_temp_f_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("Wells Forebay T, Clean")

# WEL, tailrace
WEL_temp_t_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> WEL_temp_t_long_2

ggplot(WEL_temp_t_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("Wells Tailrace T, Original")

# run of values in 2007 and run of values in 2008 and run of values in 2009 and run of values in 2017
# subset(WEL_temp_t_long, year == 2007)
# 2007: nonsense starts on day 161 and ends on day 260

# subset(WEL_temp_t_long, year == 2008)
# 2008: nonsense starts on day 79 and ends on day 182

# subset(WEL_temp_t_long, year == 2009)
# 2009: nonsense starts on day 272 and ends on day 300

# subset(WEL_temp_t_long, year == 2017)
# 2017: nonsense starts on day 177 and ends on day 197

WEL_temp_t_long %>% 
  filter(!(year == 2007 & day >= 161 & day <=260)) %>% 
  filter(!(year == 2008 & day >= 79 & day <=182)) %>% 
  filter(!(year == 2009 & day >= 272 & day <=300)) %>% 
  filter(!(year == 2017 & day >= 177 & day <=197)) -> WEL_temp_t_long_clean

ggplot(WEL_temp_t_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("Wells Tailrace T, Clean")
```

```{r filter_RIS}
# RIS, forebay
RIS_temp_f_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> RIS_temp_f_long_2

ggplot(RIS_temp_f_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RIS Forebay T, Original")

# so there are three flat runs, two in 2005 and one in 2006. Let's filter that out based on lag/lead of at least three of the same value in a row
# there's also a stupid run in 2007, drop that: day 161-281
# subset(RIS_temp_f_long, year == 2007)

RIS_temp_f_long %>% 
  filter(!(year == 2007 & day >= 161 & day <=281)) %>% 
    filter(!(temp == lag(temp) & temp == lag(temp, 2) |
             temp == lead(temp) & temp == lead(temp, 2))) -> RIS_temp_f_long_clean

ggplot(RIS_temp_f_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RIS Forebay T, Clean")

# RIS, tailrace
RIS_temp_t_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> RIS_temp_t_long_2

ggplot(RIS_temp_t_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RIS Tailrace T, Original")
# just looks like two flat runs, one in 2005 and one in 2006

# there's also a single value in 2006 that's totally messing up the linear interpolation that we need to drop on day 101
# subset(RIS_temp_t_long, year == 2006)

RIS_temp_t_long %>% 
  filter(!(year == 2006 & day == 101)) %>% 
    filter(!(temp == lag(temp) & temp == lag(temp, 2) |
             temp == lead(temp) & temp == lead(temp, 2))) -> RIS_temp_t_long_clean

ggplot(RIS_temp_t_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RIS Tailrace T, Clean")
```

```{r filter_RRE}
# RRE, forebay
RRE_temp_f_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> RRE_temp_f_long_2

ggplot(RRE_temp_f_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RRE Forebay T, Original")

# so there are four flat runs, two in 2005 and two in 2006. Let's filter that out based on lag/lead of at least three of the same value in a row

RRE_temp_f_long %>% 
    filter(!(temp == lag(temp) & temp == lag(temp, 2) |
             temp == lead(temp) & temp == lead(temp, 2))) -> RRE_temp_f_long_clean

ggplot(RRE_temp_f_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RRE Forebay T, Clean")

# RRE, tailrace
RRE_temp_t_long %>% 
  mutate(date = ymd(date)) %>% 
  mutate(day = yday(date)) %>% 
  mutate(year = as.factor(year)) -> RRE_temp_t_long_2

ggplot(RRE_temp_t_long_2, aes(x = day, y = temp, color = year)) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RRE Tailrace T, Original")
# just looks like three flat runs, two in 2005 and one in 2006

RRE_temp_t_long %>% 
    filter(!(temp == lag(temp) & temp == lag(temp, 2) |
             temp == lead(temp) & temp == lead(temp, 2))) -> RRE_temp_t_long_clean

ggplot(RRE_temp_t_long_clean, aes(x = day, y = temp, color = as.factor(year))) +
  geom_point() +
  scale_color_tableau(palette = "Tableau 20") +
  ggtitle("RRE Tailrace T, Clean")
```

For outliers: Any values that are +/- 4 degrees away from the long-term mean for that day will be dropped

```{r}
BON_temps_clean <- filter_outliers_temp(forebay_t = BON_temp_f_long, tailrace_t = BON_temp_t_long, dam = "BON")
ICH_temps_clean <- filter_outliers_temp(forebay_t = ICH_temp_f_long, tailrace_t = ICH_temp_t_long, dam = "ICH")
JDA_temps_clean <- filter_outliers_temp(forebay_t = JDA_temp_f_long, tailrace_t = JDA_temp_t_long, dam = "JDA")
LGO_temps_clean <- filter_outliers_temp(forebay_t = LGO_temp_f_long, tailrace_t = LGO_temp_t_long, dam = "LGO")
LGR_temps_clean <- filter_outliers_temp(forebay_t = LGR_temp_f_long, tailrace_t = LGR_temp_t_long, dam = "LGR")
LMO_temps_clean <- filter_outliers_temp(forebay_t = LMO_temp_f_long, tailrace_t = LMO_temp_t_long, dam = "LMO")
MCN_temps_clean <- filter_outliers_temp(forebay_t = MCN_temp_f_long, tailrace_t = MCN_temp_t_long, dam = "MCN")
PRA_temps_clean <- filter_outliers_temp(forebay_t = PRA_temp_f_long, tailrace_t = PRA_temp_t_long, dam = "PRA")
RIS_temps_clean <- filter_outliers_temp(forebay_t = RIS_temp_f_long_clean, tailrace_t = RIS_temp_t_long_clean, dam = "RIS")
RRE_temps_clean <- filter_outliers_temp(forebay_t = RRE_temp_f_long_clean, tailrace_t = RRE_temp_t_long_clean, dam = "RRE")
TDA_temps_clean <- filter_outliers_temp(forebay_t = TDA_temp_f_long, tailrace_t = TDA_temp_t_long, dam = "TDA")
WAN_temps_clean <- filter_outliers_temp(forebay_t = WAN_temp_f_long, tailrace_t = WAN_temp_t_long, dam = "WAN")
WEL_temps_clean <- filter_outliers_temp(forebay_t = WEL_temp_f_long_clean, tailrace_t = WEL_temp_t_long_clean, dam = "WEL")
  
```

#### get the upper columbia dam temperature relationships with Wanapum

```{r upper_columbia_dam_t_relationships}
dplyr::rename(WAN_temps_clean[[2]], WAN_tailrace_temp = tailrace_temp) %>% 
  left_join(.,dplyr::rename(WEL_temps_clean[[2]], WEL_tailrace_temp = tailrace_temp), by = "date") %>% 
  left_join(.,dplyr::rename(RRE_temps_clean[[2]], RRE_tailrace_temp = tailrace_temp), by = "date") %>% 
  left_join(.,dplyr::rename(RIS_temps_clean[[2]], RIS_tailrace_temp = tailrace_temp), by = "date") %>% 
  left_join(.,dplyr::rename(PRA_temps_clean[[2]], PRA_tailrace_temp = tailrace_temp), by = "date") -> UC_tailrace_t

ggplot(UC_tailrace_t, aes(x = WAN_tailrace_temp, y = WEL_tailrace_temp)) +
  geom_point() +
  ggtitle("WEL v WAN")

ggplot(UC_tailrace_t, aes(x = WAN_tailrace_temp, y = RRE_tailrace_temp)) +
  geom_point() +
  ggtitle("RRE v WAN")

ggplot(UC_tailrace_t, aes(x = WAN_tailrace_temp, y = RIS_tailrace_temp)) +
  geom_point() +
  ggtitle("RIS v WAN")

ggplot(UC_tailrace_t, aes(x = WAN_tailrace_temp, y = PRA_tailrace_temp)) +
  geom_point() +
  ggtitle("PRA v WAN")

# it's a very tight relationship for all of them - fit linear regression and save coefficients
WEL_WAN_lm <- lm(WEL_tailrace_temp ~ WAN_tailrace_temp, data = UC_tailrace_t)
WEL_WAN_coef <- WEL_WAN_lm$coefficients
RRE_WAN_lm <- lm(RRE_tailrace_temp ~ WAN_tailrace_temp, data = UC_tailrace_t)
RRE_WAN_coef <- RRE_WAN_lm$coefficients
RIS_WAN_lm <- lm(RIS_tailrace_temp ~ WAN_tailrace_temp, data = UC_tailrace_t)
RIS_WAN_coef <- RIS_WAN_lm$coefficients
PRA_WAN_lm <- lm(PRA_tailrace_temp ~ WAN_tailrace_temp, data = UC_tailrace_t)
PRA_WAN_coef <- PRA_WAN_lm$coefficients


```

### Generate the full temperature time series from which to generate windows

```{r full_temp_ts}

# a function just for upper columbia dams with relationship to WAN temperatures
UC_temp <- function(temperature_df, WAN_coef, WAN_temp_ts){
  WAN_temp_ts <- dplyr::select(WAN_temp_ts, date, temp)
  
  temperature_df %>% 
    mutate(year = year(date)) %>% 
    left_join(dplyr::rename(WAN_temp_ts, WAN_temp = temp), by = "date") %>% 
    mutate(temp = ifelse(year <= 2013 & date >= ymd("2006-05-31") & source == "linear_interpolation",
                         WAN_coef[1] + WAN_coef[2]*WAN_temp, temp)) %>% 
    mutate(source = ifelse(year <= 2013 & date >= ymd("2006-05-31") & source == "linear_interpolation", "WAN_interpolation", source)) %>% 
    dplyr::select(-year)-> temperature_df_WAN_int
  
  return(temperature_df_WAN_int)
  
}

# generate full time series and plot thereof for modeling
full_temp_ts <- function(tailrace_temp, forebay_temp, dam, 
                         upper_columbia_dam = FALSE, WAN_coef = NA, WAN_temp_ts = NA){ # these arguments are only needed for the UC dams
  # Generate the full sequence of dates for which we need temperatures
  temperature_df_skeleton <- data.frame(date = seq(ymd('2005-06-01'),ymd('2022-12-31'), by = 'days'),
                               temp = NA, source = NA)
  
  # Populate with tailrace data
  temperature_df_skeleton %>% 
    left_join(tailrace_temp, by = "date") %>% 
    left_join(forebay_temp, by = "date") %>% 
    # use tailrace temperature first, forebay temperature second
    mutate(temp = ifelse(!(is.na(tailrace_temp)), tailrace_temp, forebay_temp)) %>% 
    # note source
    mutate(source = ifelse(!(is.na(tailrace_temp)), "tailrace", 
                           ifelse(!(is.na(forebay_temp)),"forebay", NA))) %>% 
    # if the gap for NA values is less than a week, linearly interpolate
    mutate(source = ifelse(is.na(temp), "linear_interpolation", source)) %>% 
    mutate(temp = na.approx(temp)) -> temperature_df
  
  if(upper_columbia_dam == TRUE) {
    temperature_df <- UC_temp(temperature_df = temperature_df, WAN_coef = WAN_coef, WAN_temp_ts = WAN_temp_ts)
  }
  
  # plot to check
  temperature_df %>% 
    mutate(year = year(date)) %>% 
    mutate(day = yday(date)) -> temperature_df_forplot
  
  temp_annual_plot <- ggplot(temperature_df_forplot, aes(x = day, y = temp, color = source)) +
    geom_point() +
    facet_wrap(~year) +
    ggtitle(dam)
  
  return(list(temperature_df, temp_annual_plot))
}

# generate plots
# upper columbia
full_temp_ts(tailrace_temp = WAN_temps_clean[[2]], forebay_temp = WAN_temps_clean[[1]], dam = "WAN")[[2]]
WAN_temp_ts <- full_temp_ts(tailrace_temp = WAN_temps_clean[[2]], forebay_temp = WAN_temps_clean[[1]], dam = "WAN")[[1]]
full_temp_ts(tailrace_temp = PRA_temps_clean[[2]], forebay_temp = PRA_temps_clean[[1]], dam = "PRA",
             upper_columbia_dam = TRUE, WAN_coef = PRA_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[2]]
full_temp_ts(tailrace_temp = RIS_temps_clean[[2]], forebay_temp = RIS_temps_clean[[1]], dam = "RIS",
             upper_columbia_dam = TRUE, WAN_coef = RIS_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[2]]
full_temp_ts(tailrace_temp = RRE_temps_clean[[2]], forebay_temp = RRE_temps_clean[[1]], dam = "RRE",
             upper_columbia_dam = TRUE, WAN_coef = RRE_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[2]]
full_temp_ts(tailrace_temp = WEL_temps_clean[[2]], forebay_temp = WEL_temps_clean[[1]], dam = "WEL",
             upper_columbia_dam = TRUE, WAN_coef = WEL_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[2]]

# middle columbia
full_temp_ts(tailrace_temp = BON_temps_clean[[2]], forebay_temp = BON_temps_clean[[1]], dam = "BON")[[2]]
full_temp_ts(tailrace_temp = TDA_temps_clean[[2]], forebay_temp = TDA_temps_clean[[1]], dam = "TDA")[[2]]
full_temp_ts(tailrace_temp = JDA_temps_clean[[2]], forebay_temp = JDA_temps_clean[[1]], dam = "JDA")[[2]]
full_temp_ts(tailrace_temp = MCN_temps_clean[[2]], forebay_temp = MCN_temps_clean[[1]], dam = "MCN")[[2]]

# snake
full_temp_ts(tailrace_temp = ICH_temps_clean[[2]], forebay_temp = ICH_temps_clean[[1]], dam = "ICH")[[2]]
full_temp_ts(tailrace_temp = LGO_temps_clean[[2]], forebay_temp = LGO_temps_clean[[1]], dam = "LGO")[[2]]
full_temp_ts(tailrace_temp = LMO_temps_clean[[2]], forebay_temp = LMO_temps_clean[[1]], dam = "LMO")[[2]]
full_temp_ts(tailrace_temp = LGR_temps_clean[[2]], forebay_temp = LGR_temps_clean[[1]], dam = "LGR")[[2]]

# generate data
# upper columbia
WAN_temp_ts <- full_temp_ts(tailrace_temp = WAN_temps_clean[[2]], forebay_temp = WAN_temps_clean[[1]], dam = "WAN")[[1]]
PRA_temp_ts <- full_temp_ts(tailrace_temp = PRA_temps_clean[[2]], forebay_temp = PRA_temps_clean[[1]], dam = "PRA",
             upper_columbia_dam = TRUE, WAN_coef = PRA_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[1]]
RIS_temp_ts <- full_temp_ts(tailrace_temp = RIS_temps_clean[[2]], forebay_temp = RIS_temps_clean[[1]], dam = "RIS",
             upper_columbia_dam = TRUE, WAN_coef = RIS_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[1]]
RRE_temp_ts <- full_temp_ts(tailrace_temp = RRE_temps_clean[[2]], forebay_temp = RRE_temps_clean[[1]], dam = "RRE",
             upper_columbia_dam = TRUE, WAN_coef = RRE_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[1]]
WEL_temp_ts <- full_temp_ts(tailrace_temp = WEL_temps_clean[[2]], forebay_temp = WEL_temps_clean[[1]], dam = "WEL",
             upper_columbia_dam = TRUE, WAN_coef = WEL_WAN_coef, WAN_temp_ts = WAN_temp_ts)[[1]]

# middle columbia
BON_temp_ts <- full_temp_ts(tailrace_temp = BON_temps_clean[[2]], forebay_temp = BON_temps_clean[[1]], dam = "BON")[[1]]
TDA_temp_ts <- full_temp_ts(tailrace_temp = TDA_temps_clean[[2]], forebay_temp = TDA_temps_clean[[1]], dam = "TDA")[[1]]
JDA_temp_ts <- full_temp_ts(tailrace_temp = JDA_temps_clean[[2]], forebay_temp = JDA_temps_clean[[1]], dam = "JDA")[[1]]
MCN_temp_ts <- full_temp_ts(tailrace_temp = MCN_temps_clean[[2]], forebay_temp = MCN_temps_clean[[1]], dam = "MCN")[[1]]

# snake
ICH_temp_ts <- full_temp_ts(tailrace_temp = ICH_temps_clean[[2]], forebay_temp = ICH_temps_clean[[1]], dam = "ICH")[[1]]
LGO_temp_ts <- full_temp_ts(tailrace_temp = LGO_temps_clean[[2]], forebay_temp = LGO_temps_clean[[1]], dam = "LGO")[[1]]
LMO_temp_ts <- full_temp_ts(tailrace_temp = LMO_temps_clean[[2]], forebay_temp = LMO_temps_clean[[1]], dam = "LMO")[[1]]
LGR_temp_ts <- full_temp_ts(tailrace_temp = LGR_temps_clean[[2]], forebay_temp = LGR_temps_clean[[1]], dam = "LGR")[[1]]

```

### calculate windows

```{r}
# so, I think that the most up to date files are in the same folders as the model runs
snake_adults_states_complete <- read.csv(here::here("stan_actual", "deteff_ESU_models", "500iter_3chain_runs", "snake", "snake_adults_states_complete.csv"), row.names = 1)
lowcol_adults_states_complete <- read.csv(here::here("stan_actual", "deteff_ESU_models", "lower_columbia", "lower_columbia_adults_states_complete.csv"), row.names = 1)
midcol_adults_states_complete <- read.csv(here::here("stan_actual", "deteff_ESU_models", "500iter_3chain_runs", "middle_columbia", "middle_columbia_adults_states_complete.csv"), row.names = 1)
uppcol_adults_states_complete <- read.csv(here::here("stan_actual", "deteff_ESU_models", "500iter_3chain_runs", "upper_columbia", "upper_columbia_adults_states_complete.csv"), row.names = 1)

# combine them all
snake_adults_states_complete %>% 
  bind_rows(., midcol_adults_states_complete) %>% 
  bind_rows(., uppcol_adults_states_complete) %>% 
  bind_rows(., lowcol_adults_states_complete) -> ASC

# now add tag code metadata, for natal origins
origin_numeric <- data.frame(natal_origin = c("Asotin_Creek", 
                                        "Clearwater_River",
                                        "Deschutes_River", 
                                        "Entiat_River", 
                                        "Fifteenmile_Creek", 
                                        "Grande_Ronde_River", 
                                        "Hood_River",
                                        "Imnaha_River",
                                        "John_Day_River", 
                                        "Methow_River", 
                                        "Okanogan_River", 
                                        "Salmon_River", 
                                        "Tucannon_River", 
                                        "Umatilla_River",
                                        "Walla_Walla_River",
                                        "Wenatchee_River", 
                                        "Yakima_River"),
                             natal_origin_numeric = seq(1,17,1))

origin_rear_actual <- read.csv(here::here("stan_actual", "origin_rear_actual.csv"), row.names = 1)
origin_rear_actual %>% 
  dplyr::rename(natal_origin_numeric = natal_origin) %>% 
  left_join(origin_numeric, by = "natal_origin_numeric") %>% 
  dplyr::select(tag_code_2, natal_origin) -> tag_code_origins

ASC %>% 
  left_join(., tag_code_origins, by = "tag_code_2") -> ASC

# also note which ESU they're from, for plotting
ESU_origins <- data.frame(natal_origin = unique(ASC$natal_origin),
                          ESU = c(rep("Snake", 6),
                                  rep("Middle Columbia", 6),
                                  rep("Upper Columbia", 4),
                                  "Lower Columbia"))

ASC %>% 
  left_join(., ESU_origins, by = "natal_origin") -> ASC

# a function that takes just one state, and finds the average amount of time to move out of that state

residence_time <- function(residence_state){
  
  # don't keep any with implicit time interpolated
  ASC %>% 
    filter(state == residence_state & tag_code_2 == lead(tag_code_2) & pathway != "implicit" & lead(pathway) != "implicit" |
             lag(state) == residence_state & tag_code_2 == lag(tag_code_2) & pathway != "implicit" & lag(pathway) != "implicit") %>% 
    mutate(date_time = ymd_hms(date_time)) -> one_state_df
  
  # make a data frame to record all of the transitions
  n_transitions <- nrow(one_state_df)/2
  passage_df <- data.frame(tag_code_2 = one_state_df$tag_code_2[seq(1,(nrow(one_state_df)-1),2)],
                           ESU = one_state_df$ESU[seq(1,(nrow(one_state_df)-1),2)],
                           natal_origin = one_state_df$natal_origin[seq(1,(nrow(one_state_df)-1),2)],
                           passage_time = NA)
  
  
  for (i in 1:nrow(passage_df)){
    passage_df$passage_time[i] <- one_state_df$date_time[(i*2)] - one_state_df$date_time[(i*2-1)]
    
  }
  
  return(passage_df)
  
}

main_mainstem_states <- c(
  "mainstem, BON to MCN",
  "mainstem, MCN to ICH or PRA",
  "mainstem, PRA to RIS",
  "mainstem, RIS to RRE",
  "mainstem, RRE to WEL",
  "mainstem, ICH to LGR",
  "mainstem, upstream of WEL",
  "mainstem, upstream of LGR")

list_quantiles <- list()

for (i in 1:length(main_mainstem_states)) {
  residence_df <- residence_time(residence_state = main_mainstem_states[i])
  
  # Look into windows - show: 1) median of the whole distribution, 
  # and what cutoff you'd need to capture 50%, 80%, and 95% of fish residence time
  quantiles <- quantile(residence_df$passage_time, probs = c(0.5, 0.8, 0.95))
  list_quantiles[[i]] <- quantiles

  
}

# make an actual table
quantiles_table <- data.frame(reach = main_mainstem_states,
                              t50 = c(list_quantiles[[1]][1],
                                       list_quantiles[[2]][1],
                                       list_quantiles[[3]][1],
                                       list_quantiles[[4]][1],
                                       list_quantiles[[5]][1],
                                       list_quantiles[[6]][1],
                                      list_quantiles[[7]][1],
                                      list_quantiles[[8]][1]),
                              t80 = c(list_quantiles[[1]][2],
                                       list_quantiles[[2]][2],
                                       list_quantiles[[3]][2],
                                       list_quantiles[[4]][2],
                                       list_quantiles[[5]][2],
                                       list_quantiles[[6]][2],
                                      list_quantiles[[7]][2],
                                      list_quantiles[[8]][2]),
                              t95 = c(list_quantiles[[1]][3],
                                       list_quantiles[[2]][3],
                                       list_quantiles[[3]][3],
                                       list_quantiles[[4]][3],
                                       list_quantiles[[5]][3],
                                       list_quantiles[[6]][3],
                                      list_quantiles[[7]][3],
                                      list_quantiles[[8]][3]))

# write.csv(quantiles_table, here::here("covariate_data", "reach_quantiles.csv"))
```

### export temperature data using window approach

```{r}
# Re-export, using reach-specific residence time windows
# quantiles <- read.csv(here::here("covariate_data", "reach_quantiles.csv"), row.names = 1)

# round the median to nearest whole day
quantiles_table %>% 
  mutate(median = round(t50)) -> quantiles_table

# match them using outflow

# use a function
window_temp <- function(temp_data, median_time){
  temp_data %>% 
  mutate(window_temp = NA) -> temp_data

# loop to get all windows
for (i in 1:nrow(temp_data)){
  temp_data$window_temp[i] <- mean(subset(temp_data, date >= temp_data$date[i] & date <= temp_data$date[i] + days(x = median_time))$temp)
}
  
  return(temp_data)
}

# Bonneville Dam, for mainstem, BON to MCN reach
BON_window_temp <- window_temp(temp_data = BON_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, BON to MCN")$median)

# McNary Dam, for mainstem, MCN to ICH or PRA reach
MCN_window_temp <- window_temp(temp_data = MCN_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, MCN to ICH or PRA")$median)

# PRA Dam, for PRA to RIS reach
PRA_window_temp <- window_temp(temp_data = PRA_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, PRA to RIS")$median)

# RIS Dam, for RIS to RRE reach
RIS_window_temp <- window_temp(temp_data = RIS_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, RIS to RRE")$median)

# RRE Dam, for RRE to WEL reach
RRE_window_temp <- window_temp(temp_data = RRE_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, RRE to WEL")$median)

# Ice Harbor Dam, for ICH to LGR reach
ICH_window_temp <- window_temp(temp_data = ICH_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, ICH to LGR")$median)

# Wells Dam, for upstream of WEL reach
WEL_window_temp <- window_temp(temp_data = WEL_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, upstream of WEL")$median)

# Lower Granite Dam, for upstream of LGR reach
LGR_window_temp <- window_temp(temp_data = LGR_temp_ts, median_time = subset(quantiles_table, reach == "mainstem, upstream of LGR")$median)

# export all of these
write.csv(BON_window_temp, here::here("covariate_data", "for_model", "temp", "BON_window_temp.csv"), row.names = FALSE)
write.csv(MCN_window_temp, here::here("covariate_data", "for_model", "temp", "MCN_window_temp.csv"), row.names = FALSE)
write.csv(PRA_window_temp, here::here("covariate_data", "for_model", "temp", "PRA_window_temp.csv"), row.names = FALSE)
write.csv(RIS_window_temp, here::here("covariate_data", "for_model", "temp", "RIS_window_temp.csv"), row.names = FALSE)
write.csv(RRE_window_temp, here::here("covariate_data", "for_model", "temp", "RRE_window_temp.csv"), row.names = FALSE)
write.csv(ICH_window_temp, here::here("covariate_data", "for_model", "temp", "ICH_window_temp.csv"), row.names = FALSE)
write.csv(WEL_window_temp, here::here("covariate_data", "for_model", "temp", "WEL_window_temp.csv"), row.names = FALSE)
write.csv(LGR_window_temp, here::here("covariate_data", "for_model", "temp", "LGR_window_temp.csv"), row.names = FALSE)

```

#### export in the format needed for stan
```{r}
dplyr::rename(dplyr::select(BON_window_temp, date, window_temp), BON = window_temp) %>% 
  left_join(dplyr::rename(dplyr::select(MCN_window_temp, date, window_temp), MCN = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(PRA_window_temp, date, window_temp), PRA = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(RIS_window_temp, date, window_temp), RIS = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(RRE_window_temp, date, window_temp), RRE = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(WEL_window_temp, date, window_temp), WEL = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(ICH_window_temp, date, window_temp), ICH = window_temp), by = "date") %>% 
  left_join(dplyr::rename(dplyr::select(LGR_window_temp, date, window_temp), LGR = window_temp), by = "date") %>% 
  mutate(index = row_number()) %>% 
  relocate(index) %>% 
  dplyr::select(-date) %>% 
  column_to_rownames("index") -> window_temps

# now, z-score every column
window_temps %>% 
  mutate(BON = (BON - mean(BON))/sd(BON)) %>% 
  mutate(MCN = (MCN - mean(MCN))/sd(MCN)) %>% 
  mutate(PRA = (PRA - mean(PRA))/sd(PRA)) %>% 
  mutate(RIS = (RIS - mean(RIS))/sd(RIS)) %>% 
  mutate(RRE = (RRE - mean(RRE))/sd(RRE)) %>% 
  mutate(WEL = (WEL - mean(WEL))/sd(WEL)) %>% 
  mutate(ICH = (ICH - mean(ICH))/sd(ICH)) %>% 
  mutate(LGR = (LGR - mean(LGR))/sd(LGR)) -> window_temps
  

write.csv(window_temps, here::here("covariate_data", "for_model", "window_temps_for_stan.csv"))
write.csv(window_temps, "/Users/markusmin/Documents/CBR/steelhead/stan_actual/rear_temp/upper_columbia/window_temps_for_stan.csv")

```




